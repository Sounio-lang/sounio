// Sounio Standard Library: Differentiable Effects
//
// Neural computation as an algebraic effect. This enables:
// - Automatic differentiation through effect handlers
// - Epistemic propagation through gradient flow
// - Clean separation of forward/backward passes
// - Composability with other effects (search, construct)
//
// Key insight: Differentiation is a computational effect, not a type.
// The handler manages the tape and gradient accumulation.

import epistemic::Knowledge;
import epistemic::Confidence;
import epistemic::Source;
import epistemic::bayesian::BetaConfidence;

// =============================================================================
// Tensor Types (Minimal for Geometry LM)
// =============================================================================

/// N-dimensional tensor with shape tracking
struct Tensor {
    /// Flat data storage
    data: Vec[f32],
    /// Shape (dimensions)
    shape: Vec[usize],
    /// Whether this tensor requires gradient
    requires_grad: bool,
    /// Gradient (same shape as data)
    grad: Option[Vec[f32]],
}

impl Tensor {
    /// Create tensor from data and shape
    fn new(data: Vec[f32], shape: Vec[usize]) -> Tensor {
        Tensor {
            data: data,
            shape: shape,
            requires_grad: false,
            grad: None,
        }
    }

    /// Create tensor requiring gradient (parameter)
    fn param(data: Vec[f32], shape: Vec[usize]) -> Tensor {
        Tensor {
            data: data,
            shape: shape,
            requires_grad: true,
            grad: Some(vec![0.0; data.len()]),
        }
    }

    /// Create zeros
    fn zeros(shape: Vec[usize]) -> Tensor {
        let size = shape.iter().product();
        Tensor::new(vec![0.0; size], shape)
    }

    /// Create ones
    fn ones(shape: Vec[usize]) -> Tensor {
        let size = shape.iter().product();
        Tensor::new(vec![1.0; size], shape)
    }

    /// Total number of elements
    fn numel(self) -> usize {
        self.data.len()
    }

    /// Get element at flat index
    fn get(self, idx: usize) -> f32 {
        self.data[idx]
    }

    /// Set element at flat index
    fn set(mut self, idx: usize, val: f32) {
        self.data[idx] = val;
    }

    /// Zero gradients
    fn zero_grad(mut self) {
        if let Some(ref mut g) = self.grad {
            for x in g.iter_mut() {
                *x = 0.0;
            }
        }
    }

    /// Accumulate gradient
    fn accumulate_grad(mut self, grad: &[f32]) {
        if let Some(ref mut g) = self.grad {
            for (i, x) in g.iter_mut().enumerate() {
                *x += grad[i];
            }
        }
    }
}

/// Epistemic tensor - tensor with confidence
struct EpistemicTensor {
    /// Underlying tensor
    tensor: Tensor,
    /// Confidence in values (can vary per-element or be scalar)
    confidence: BetaConfidence,
    /// Source of this tensor
    source: Source,
}

impl EpistemicTensor {
    /// Create from tensor with uniform confidence
    fn new(tensor: Tensor, confidence: f64) -> EpistemicTensor {
        EpistemicTensor {
            tensor: tensor,
            confidence: BetaConfidence::from_confidence(confidence, 10.0),
            source: Source::Unknown,
        }
    }

    /// Create from model prediction
    fn from_model(tensor: Tensor, model_name: &str, confidence: f64) -> EpistemicTensor {
        EpistemicTensor {
            tensor: tensor,
            confidence: BetaConfidence::from_confidence(confidence, 5.0), // Lower effective n for model
            source: Source::ModelPrediction {
                model: model_name.to_string(),
                version: None,
            },
        }
    }

    /// Compute confidence from softmax entropy
    /// High entropy = low confidence, low entropy = high confidence
    fn confidence_from_entropy(logits: &Tensor) -> f64 {
        // Softmax
        let max_val = logits.data.iter().cloned().fold(f32::NEG_INFINITY, f32::max);
        let exp_sum: f32 = logits.data.iter().map(|x| (x - max_val).exp()).sum();
        let probs: Vec[f32] = logits.data.iter().map(|x| (x - max_val).exp() / exp_sum).collect();

        // Entropy: -sum(p * log(p))
        let entropy: f32 = probs.iter()
            .filter(|&&p| p > 1e-10)
            .map(|&p| -p * p.ln())
            .sum();

        // Normalize by max entropy (log(n))
        let max_entropy = (logits.data.len() as f32).ln();
        let normalized_entropy = entropy / max_entropy;

        // Convert to confidence: low entropy = high confidence
        (1.0 - normalized_entropy as f64).clamp(0.1, 0.99)
    }

    /// Decay confidence through gradient step
    fn decay_confidence(mut self, factor: f64) -> EpistemicTensor {
        // Model confidence in gradient-updated values
        let current_mean = self.confidence.mean();
        self.confidence = BetaConfidence::from_confidence(
            current_mean * factor,
            self.confidence.sample_size() * 0.9, // Reduce certainty
        );
        self
    }
}

// =============================================================================
// Differentiable Effect
// =============================================================================

/// Effect for differentiable computation
///
/// This effect captures the context of gradient-tracked computation.
/// Handlers can implement various autodiff strategies:
/// - Eager (immediate gradient computation)
/// - Lazy (tape-based, compute on backward)
/// - Checkpointed (memory-efficient)
effect gradient {
    /// Record a forward operation
    fn record_op(op: DiffOp, inputs: Vec[TensorId], output: TensorId);

    /// Get tensor by ID
    fn get_tensor(id: TensorId) -> Tensor;

    /// Store tensor, return ID
    fn store_tensor(tensor: Tensor) -> TensorId;

    /// Trigger backward pass from a tensor
    fn backward(id: TensorId);

    /// Get current gradient for a tensor
    fn get_grad(id: TensorId) -> Option[Tensor];
}

/// Tensor identifier for tape tracking
type TensorId = usize;

/// Differentiable operations
enum DiffOp {
    /// Matrix multiply: C = A @ B
    MatMul,
    /// Element-wise add: C = A + B
    Add,
    /// Element-wise multiply: C = A * B
    Mul,
    /// ReLU activation
    ReLU,
    /// Softmax
    Softmax,
    /// Layer normalization
    LayerNorm { eps: f32 },
    /// Embedding lookup
    Embedding,
    /// Cross entropy loss
    CrossEntropy,
    /// Mean squared error
    MSE,
}

/// A recorded operation on the tape
struct TapeEntry {
    op: DiffOp,
    inputs: Vec[TensorId],
    output: TensorId,
    /// Cached values for backward pass
    cache: Option[Vec[Tensor]],
}

// =============================================================================
// Tape-Based Autodiff Handler
// =============================================================================

/// Handler implementing reverse-mode autodiff via tape
handler autodiff_handler for gradient {
    /// Tensor storage
    tensors: Vec[Tensor],
    /// Operation tape
    tape: Vec[TapeEntry],
    /// Gradients (indexed by tensor ID)
    grads: Map[TensorId, Tensor],
    /// Epistemic decay factor per backward step
    epistemic_decay: f64,
}

impl autodiff_handler {
    fn new() -> autodiff_handler {
        autodiff_handler {
            tensors: vec![],
            tape: vec![],
            grads: Map::new(),
            epistemic_decay: 0.99,
        }
    }

    /// Handle: store_tensor
    fn handle_store_tensor(mut self, tensor: Tensor) -> TensorId {
        let id = self.tensors.len();
        self.tensors.push(tensor);
        id
    }

    /// Handle: get_tensor
    fn handle_get_tensor(self, id: TensorId) -> Tensor {
        self.tensors[id].clone()
    }

    /// Handle: record_op
    fn handle_record_op(mut self, op: DiffOp, inputs: Vec[TensorId], output: TensorId) {
        self.tape.push(TapeEntry {
            op: op,
            inputs: inputs,
            output: output,
            cache: None,
        });
    }

    /// Handle: backward
    fn handle_backward(mut self, loss_id: TensorId) {
        // Initialize gradient of loss to 1.0
        let loss_tensor = &self.tensors[loss_id];
        let ones = Tensor::ones(loss_tensor.shape.clone());
        self.grads.insert(loss_id, ones);

        // Traverse tape in reverse
        for entry in self.tape.iter().rev() {
            let out_grad = match self.grads.get(&entry.output) {
                Some(g) => g.clone(),
                None => continue,
            };

            // Compute input gradients based on operation
            let input_grads = self.compute_backward(&entry.op, &entry.inputs, &out_grad);

            // Accumulate into input gradients
            for (i, in_id) in entry.inputs.iter().enumerate() {
                if let Some(in_grad) = input_grads.get(i) {
                    self.grads.entry(*in_id)
                        .and_modify(|g| {
                            for (j, v) in g.data.iter_mut().enumerate() {
                                *v += in_grad.data[j];
                            }
                        })
                        .or_insert(in_grad.clone());

                    // Also accumulate into tensor's grad if it requires_grad
                    if self.tensors[*in_id].requires_grad {
                        self.tensors[*in_id].accumulate_grad(&in_grad.data);
                    }
                }
            }
        }
    }

    /// Handle: get_grad
    fn handle_get_grad(self, id: TensorId) -> Option[Tensor] {
        self.grads.get(&id).cloned()
    }

    /// Compute backward pass for an operation
    fn compute_backward(self, op: &DiffOp, inputs: &[TensorId], out_grad: &Tensor) -> Vec[Tensor] {
        match op {
            DiffOp::Add => {
                // d(A + B)/dA = 1, d(A + B)/dB = 1
                vec![out_grad.clone(), out_grad.clone()]
            },
            DiffOp::Mul => {
                // d(A * B)/dA = B, d(A * B)/dB = A
                let a = &self.tensors[inputs[0]];
                let b = &self.tensors[inputs[1]];

                let grad_a: Vec[f32] = out_grad.data.iter()
                    .zip(b.data.iter())
                    .map(|(g, bv)| g * bv)
                    .collect();
                let grad_b: Vec[f32] = out_grad.data.iter()
                    .zip(a.data.iter())
                    .map(|(g, av)| g * av)
                    .collect();

                vec![
                    Tensor::new(grad_a, a.shape.clone()),
                    Tensor::new(grad_b, b.shape.clone()),
                ]
            },
            DiffOp::ReLU => {
                // d(ReLU(x))/dx = 1 if x > 0, else 0
                let input = &self.tensors[inputs[0]];
                let grad: Vec[f32] = input.data.iter()
                    .zip(out_grad.data.iter())
                    .map(|(x, g)| if *x > 0.0 { *g } else { 0.0 })
                    .collect();
                vec![Tensor::new(grad, input.shape.clone())]
            },
            DiffOp::MatMul => {
                // d(A @ B)/dA = out_grad @ B^T
                // d(A @ B)/dB = A^T @ out_grad
                // Simplified for 2D matrices
                let a = &self.tensors[inputs[0]];
                let b = &self.tensors[inputs[1]];

                // Assuming a: [M, K], b: [K, N], out_grad: [M, N]
                let m = a.shape[0];
                let k = a.shape[1];
                let n = b.shape[1];

                // grad_a = out_grad @ b^T: [M, N] @ [N, K] = [M, K]
                let mut grad_a = vec![0.0f32; m * k];
                for i in 0..m {
                    for j in 0..k {
                        for l in 0..n {
                            grad_a[i * k + j] += out_grad.data[i * n + l] * b.data[j * n + l];
                        }
                    }
                }

                // grad_b = a^T @ out_grad: [K, M] @ [M, N] = [K, N]
                let mut grad_b = vec![0.0f32; k * n];
                for i in 0..k {
                    for j in 0..n {
                        for l in 0..m {
                            grad_b[i * n + j] += a.data[l * k + i] * out_grad.data[l * n + j];
                        }
                    }
                }

                vec![
                    Tensor::new(grad_a, vec![m, k]),
                    Tensor::new(grad_b, vec![k, n]),
                ]
            },
            _ => {
                // Other ops - return zero grads as placeholder
                inputs.iter().map(|id| {
                    let t = &self.tensors[*id];
                    Tensor::zeros(t.shape.clone())
                }).collect()
            }
        }
    }

    /// Clear the tape (call after optimizer step)
    fn clear(mut self) {
        self.tape.clear();
        self.grads.clear();
    }
}

// =============================================================================
// Differentiable Operations (Using Effect)
// =============================================================================

/// Matrix multiplication with gradient tracking
fn matmul(a: TensorId, b: TensorId) -> TensorId with gradient {
    let a_tensor = get_tensor(a);
    let b_tensor = get_tensor(b);

    // Compute C = A @ B
    let m = a_tensor.shape[0];
    let k = a_tensor.shape[1];
    let n = b_tensor.shape[1];

    let mut c_data = vec![0.0f32; m * n];
    for i in 0..m {
        for j in 0..n {
            for l in 0..k {
                c_data[i * n + j] += a_tensor.data[i * k + l] * b_tensor.data[l * n + j];
            }
        }
    }

    let c = Tensor::new(c_data, vec![m, n]);
    let c_id = store_tensor(c);
    record_op(DiffOp::MatMul, vec![a, b], c_id);
    c_id
}

/// Element-wise addition with gradient tracking
fn add(a: TensorId, b: TensorId) -> TensorId with gradient {
    let a_tensor = get_tensor(a);
    let b_tensor = get_tensor(b);

    let c_data: Vec[f32] = a_tensor.data.iter()
        .zip(b_tensor.data.iter())
        .map(|(x, y)| x + y)
        .collect();

    let c = Tensor::new(c_data, a_tensor.shape.clone());
    let c_id = store_tensor(c);
    record_op(DiffOp::Add, vec![a, b], c_id);
    c_id
}

/// Element-wise multiplication with gradient tracking
fn mul(a: TensorId, b: TensorId) -> TensorId with gradient {
    let a_tensor = get_tensor(a);
    let b_tensor = get_tensor(b);

    let c_data: Vec[f32] = a_tensor.data.iter()
        .zip(b_tensor.data.iter())
        .map(|(x, y)| x * y)
        .collect();

    let c = Tensor::new(c_data, a_tensor.shape.clone());
    let c_id = store_tensor(c);
    record_op(DiffOp::Mul, vec![a, b], c_id);
    c_id
}

/// ReLU activation with gradient tracking
fn relu(x: TensorId) -> TensorId with gradient {
    let x_tensor = get_tensor(x);

    let y_data: Vec[f32] = x_tensor.data.iter()
        .map(|&v| if v > 0.0 { v } else { 0.0 })
        .collect();

    let y = Tensor::new(y_data, x_tensor.shape.clone());
    let y_id = store_tensor(y);
    record_op(DiffOp::ReLU, vec![x], y_id);
    y_id
}

/// Softmax with gradient tracking
fn softmax(x: TensorId) -> TensorId with gradient {
    let x_tensor = get_tensor(x);

    let max_val = x_tensor.data.iter().cloned().fold(f32::NEG_INFINITY, f32::max);
    let exp_sum: f32 = x_tensor.data.iter().map(|v| (v - max_val).exp()).sum();
    let y_data: Vec[f32] = x_tensor.data.iter()
        .map(|v| (v - max_val).exp() / exp_sum)
        .collect();

    let y = Tensor::new(y_data, x_tensor.shape.clone());
    let y_id = store_tensor(y);
    record_op(DiffOp::Softmax, vec![x], y_id);
    y_id
}

// =============================================================================
// Simple Neural Network Layers
// =============================================================================

/// Linear layer: y = x @ W + b
struct Linear {
    weight: TensorId,
    bias: TensorId,
    in_features: usize,
    out_features: usize,
}

impl Linear {
    /// Create linear layer with random initialization
    fn new(in_features: usize, out_features: usize) -> Linear with gradient {
        // Xavier initialization
        let scale = (2.0 / (in_features + out_features) as f32).sqrt();
        let weight_data: Vec[f32] = (0..in_features * out_features)
            .map(|_| (rand::random::<f32>() - 0.5) * 2.0 * scale)
            .collect();
        let bias_data = vec![0.0f32; out_features];

        let weight = Tensor::param(weight_data, vec![in_features, out_features]);
        let bias = Tensor::param(bias_data, vec![out_features]);

        Linear {
            weight: store_tensor(weight),
            bias: store_tensor(bias),
            in_features: in_features,
            out_features: out_features,
        }
    }

    /// Forward pass
    fn forward(self, x: TensorId) -> TensorId with gradient {
        let wx = matmul(x, self.weight);
        add(wx, self.bias)
    }
}

/// Simple MLP for construction suggestion
struct ConstructionMLP {
    layers: Vec[Linear],
    hidden_dim: usize,
}

impl ConstructionMLP {
    fn new(input_dim: usize, hidden_dim: usize, output_dim: usize, num_layers: usize) -> ConstructionMLP with gradient {
        let mut layers = vec![];

        // Input layer
        layers.push(Linear::new(input_dim, hidden_dim));

        // Hidden layers
        for _ in 1..num_layers - 1 {
            layers.push(Linear::new(hidden_dim, hidden_dim));
        }

        // Output layer
        layers.push(Linear::new(hidden_dim, output_dim));

        ConstructionMLP {
            layers: layers,
            hidden_dim: hidden_dim,
        }
    }

    /// Forward pass with ReLU activations
    fn forward(self, x: TensorId) -> TensorId with gradient {
        let mut h = x;

        for (i, layer) in self.layers.iter().enumerate() {
            h = layer.forward(h);
            // ReLU on all but last layer
            if i < self.layers.len() - 1 {
                h = relu(h);
            }
        }

        h
    }

    /// Forward with epistemic output
    fn forward_epistemic(self, x: TensorId) -> EpistemicTensor with gradient {
        let logits_id = self.forward(x);
        let logits = get_tensor(logits_id);

        // Compute confidence from entropy
        let confidence = EpistemicTensor::confidence_from_entropy(&logits);

        // Apply softmax for probabilities
        let probs_id = softmax(logits_id);
        let probs = get_tensor(probs_id);

        EpistemicTensor::from_model(probs, "construction_mlp", confidence)
    }
}

// =============================================================================
// Optimizer
// =============================================================================

/// Simple SGD optimizer
struct SGD {
    learning_rate: f32,
    parameters: Vec[TensorId],
}

impl SGD {
    fn new(parameters: Vec[TensorId], lr: f32) -> SGD {
        SGD {
            learning_rate: lr,
            parameters: parameters,
        }
    }

    /// Perform optimization step
    fn step(self) with gradient {
        for param_id in &self.parameters {
            if let Some(grad) = get_grad(*param_id) {
                let mut param = get_tensor(*param_id);
                for (i, g) in grad.data.iter().enumerate() {
                    param.data[i] -= self.learning_rate * g;
                }
                // Note: In real impl, would need to update in storage
            }
        }
    }

    /// Zero all gradients
    fn zero_grad(self) with gradient {
        for param_id in &self.parameters {
            let mut param = get_tensor(*param_id);
            param.zero_grad();
        }
    }
}

// =============================================================================
// Integration with Geometry Engine
// =============================================================================

/// Neural construction suggester for geometry proofs
struct NeuralConstructionSuggester {
    /// MLP for scoring constructions
    model: ConstructionMLP,
    /// Number of construction types
    num_constructions: usize,
    /// Embedding dimension for proof state
    state_dim: usize,
}

impl NeuralConstructionSuggester {
    fn new(state_dim: usize, hidden_dim: usize, num_constructions: usize) -> NeuralConstructionSuggester with gradient {
        NeuralConstructionSuggester {
            model: ConstructionMLP::new(state_dim, hidden_dim, num_constructions, 3),
            num_constructions: num_constructions,
            state_dim: state_dim,
        }
    }

    /// Encode proof state as tensor
    fn encode_state(self, state: &ProofState) -> Tensor {
        // Simple encoding: count of each predicate type + confidence
        let mut encoding = vec![0.0f32; self.state_dim];

        // Count predicates by type
        for (_, pred) in state.predicates.iter() {
            let idx = match pred {
                Predicate::Collin(_) => 0,
                Predicate::Concyc(_) => 1,
                Predicate::Para(_) => 2,
                Predicate::Perp(_) => 3,
                Predicate::EqLen(_) => 4,
                Predicate::EqAng(_) => 5,
                Predicate::OnCir(_) => 6,
                Predicate::Mid(_) => 7,
                _ => 8,
            };
            if idx < self.state_dim {
                encoding[idx] += 1.0;
            }
        }

        // Add overall confidence
        if self.state_dim > 10 {
            encoding[10] = state.confidence.mean() as f32;
        }

        Tensor::new(encoding, vec![1, self.state_dim])
    }

    /// Suggest constructions with epistemic confidence
    fn suggest(self, state: &ProofState) -> Vec[Construction] with gradient {
        let state_tensor = self.encode_state(state);
        let state_id = store_tensor(state_tensor);

        let output = self.model.forward_epistemic(state_id);

        // Convert probabilities to constructions
        let mut constructions = vec![];

        for (i, &prob) in output.tensor.data.iter().enumerate() {
            if prob > 0.1 {  // Threshold
                let kind = match i {
                    0 => ConstructionType::ConstructMidpoint {
                        p1: "A".to_string(),
                        p2: "B".to_string()
                    },
                    1 => ConstructionType::ConstructPerpendicular {
                        point: "C".to_string(),
                        line_p1: "A".to_string(),
                        line_p2: "B".to_string(),
                    },
                    2 => ConstructionType::ConstructCircumcircle {
                        p1: "A".to_string(),
                        p2: "B".to_string(),
                        p3: "C".to_string(),
                    },
                    _ => continue,
                };

                // Confidence combines model confidence and per-construction probability
                let conf = output.confidence.mean() * prob as f64;

                constructions.push(Construction::from_neural(
                    kind,
                    conf,
                    vec![format!("aux_{}", i)],
                ));
            }
        }

        // Sort by confidence
        constructions.sort_by(|a, b| b.confidence.value().partial_cmp(&a.confidence.value()).unwrap());

        constructions
    }
}

// =============================================================================
// Training Loop Integration
// =============================================================================

/// Loss for construction suggestion (reward if proof succeeds)
fn compute_loss(predicted: TensorId, success: bool) -> TensorId with gradient {
    let pred = get_tensor(predicted);

    // Simple reward signal: if proof succeeded, reward high-confidence predictions
    let reward = if success { 1.0f32 } else { -0.1f32 };

    // Loss = -reward * log(max_prob)
    let max_prob = pred.data.iter().cloned().fold(0.0f32, f32::max);
    let loss_val = -reward * max_prob.ln().max(-10.0);

    let loss = Tensor::new(vec![loss_val], vec![1]);
    store_tensor(loss)
}

/// Train on a single proof attempt
fn train_step(
    suggester: &NeuralConstructionSuggester,
    state: &ProofState,
    success: bool,
    optimizer: &SGD,
) with gradient {
    // Zero gradients
    optimizer.zero_grad();

    // Forward pass
    let state_tensor = suggester.encode_state(state);
    let state_id = store_tensor(state_tensor);
    let logits = suggester.model.forward(state_id);

    // Compute loss
    let loss_id = compute_loss(logits, success);

    // Backward pass
    backward(loss_id);

    // Optimizer step
    optimizer.step();
}
