//! L2: Foundation Ontologies
//!
//! These ~8,000 terms ship with the stdlib and are loaded at compiler startup.
//! - PATO: Phenotype and Trait Ontology (~2,500 terms)
//! - UO: Units of Measurement Ontology (~1,000 terms)
//! - IAO: Information Artifact Ontology (~300 terms)
//! - Schema.org: Web vocabulary (~2,850 types)
//! - FHIR R5: Healthcare resources (~1,150 resources)
//!
//! Innovation: Epistemic augmentation during load - each term gets initial Îµ
//! based on curation status and provenance.

pub mod augmentation;
pub mod fhir;
pub mod iao;
pub mod pato;
pub mod schema_org;
pub mod uo;

use std::collections::HashMap;
use std::path::PathBuf;

use crate::epistemic::{EpistemicStatus, OntologyBinding, TermId};

use super::OntologyError;

/// Foundation ontologies collection
pub struct FoundationOntologies {
    /// PATO - Phenotype and Trait Ontology
    pub pato: pato::PATOOntology,
    /// UO - Units of Measurement
    pub uo: uo::UOOntology,
    /// IAO - Information Artifact Ontology
    pub iao: iao::IAOOntology,
    /// Schema.org vocabulary
    pub schema_org: schema_org::SchemaOrgOntology,
    /// FHIR R5 resources
    pub fhir: fhir::FHIROntology,
    /// Combined index
    index: HashMap<String, FoundationTerm>,
    /// Epistemic augmentation engine
    augmenter: augmentation::EpistemicAugmenter,
}

/// Foundation term with epistemic metadata
#[derive(Debug, Clone)]
pub struct FoundationTerm {
    /// Base term entry
    pub entry: TermEntry,
    /// Initial epistemic status (computed during load)
    pub initial_epistemic: EpistemicStatus,
    /// Cross-ontology mappings (SSSOM)
    pub mappings: Vec<TermMapping>,
    /// Embedding vector (for semantic similarity)
    pub embedding: Option<Vec<f32>>,
}

/// Basic term entry
#[derive(Debug, Clone)]
pub struct TermEntry {
    /// Term identifier
    pub id: TermId,
    /// Source ontology
    pub ontology: String,
    /// Definition text
    pub definition: Option<String>,
    /// Parent terms
    pub parents: Vec<String>,
}

/// SSSOM-style mapping between terms
#[derive(Debug, Clone)]
pub struct TermMapping {
    /// Source term
    pub subject_id: String,
    /// Target term
    pub object_id: String,
    /// Mapping predicate (skos:exactMatch, skos:closeMatch, etc.)
    pub predicate: MappingPredicate,
    /// Confidence in the mapping
    pub confidence: f64,
    /// Mapping source
    pub mapping_source: String,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum MappingPredicate {
    ExactMatch,
    CloseMatch,
    BroadMatch,
    NarrowMatch,
    RelatedMatch,
}

impl MappingPredicate {
    pub fn confidence_factor(&self) -> f64 {
        match self {
            Self::ExactMatch => 1.0,
            Self::CloseMatch => 0.95,
            Self::BroadMatch => 0.8,
            Self::NarrowMatch => 0.8,
            Self::RelatedMatch => 0.6,
        }
    }
}

#[derive(Debug, Clone, Copy)]
pub enum CurationStatus {
    /// Manually curated by domain experts
    ExpertCurated,
    /// Community curated with review
    CommunityCurated,
    /// Automatically generated
    AutoGenerated,
    /// Mixed curation
    Mixed,
}

impl CurationStatus {
    pub fn base_confidence(&self) -> f64 {
        match self {
            Self::ExpertCurated => 0.98,
            Self::CommunityCurated => 0.92,
            Self::AutoGenerated => 0.75,
            Self::Mixed => 0.85,
        }
    }
}

/// Trait for ontology sources
pub trait OntologySource {
    fn terms(&self) -> Vec<TermEntry>;
    fn curation_status(&self) -> CurationStatus;
    fn provenance(&self) -> &str;
    fn get_mappings(&self, term: &TermId) -> Option<Vec<TermMapping>>;
}

impl FoundationOntologies {
    /// Load all foundation ontologies
    pub fn load() -> Result<Self, OntologyError> {
        let stdlib_path = Self::find_stdlib_path()?;
        let augmenter = augmentation::EpistemicAugmenter::new();

        // Load each ontology (bootstrap mode - use embedded data)
        let pato = pato::PATOOntology::load(&stdlib_path.join("ontology/pato.owl"))?;
        let uo = uo::UOOntology::load(&stdlib_path.join("ontology/uo.owl"))?;
        let iao = iao::IAOOntology::load(&stdlib_path.join("ontology/iao.owl"))?;
        let schema_org =
            schema_org::SchemaOrgOntology::load(&stdlib_path.join("ontology/schemaorg.jsonld"))?;
        let fhir = fhir::FHIROntology::load(&stdlib_path.join("ontology/fhir-r5.json"))?;

        // Build index with epistemic augmentation
        let mut index = HashMap::new();

        Self::index_ontology(&pato, "PATO", &augmenter, &mut index);
        Self::index_ontology(&uo, "UO", &augmenter, &mut index);
        Self::index_ontology(&iao, "IAO", &augmenter, &mut index);
        Self::index_ontology(&schema_org, "Schema", &augmenter, &mut index);
        Self::index_ontology(&fhir, "FHIR", &augmenter, &mut index);

        Ok(Self {
            pato,
            uo,
            iao,
            schema_org,
            fhir,
            index,
            augmenter,
        })
    }

    /// Create with bootstrap data (no external files needed)
    pub fn bootstrap() -> Self {
        let augmenter = augmentation::EpistemicAugmenter::new();

        let pato = pato::PATOOntology::bootstrap();
        let uo = uo::UOOntology::bootstrap();
        let iao = iao::IAOOntology::bootstrap();
        let schema_org = schema_org::SchemaOrgOntology::bootstrap();
        let fhir = fhir::FHIROntology::bootstrap();

        let mut index = HashMap::new();

        Self::index_ontology(&pato, "PATO", &augmenter, &mut index);
        Self::index_ontology(&uo, "UO", &augmenter, &mut index);
        Self::index_ontology(&iao, "IAO", &augmenter, &mut index);
        Self::index_ontology(&schema_org, "Schema", &augmenter, &mut index);
        Self::index_ontology(&fhir, "FHIR", &augmenter, &mut index);

        Self {
            pato,
            uo,
            iao,
            schema_org,
            fhir,
            index,
            augmenter,
        }
    }

    fn find_stdlib_path() -> Result<PathBuf, OntologyError> {
        // Check environment variable first
        if let Ok(path) = std::env::var("DEMETRIOS_STDLIB") {
            return Ok(path.into());
        }

        // Check relative to executable
        if let Ok(exe) = std::env::current_exe()
            && let Some(parent) = exe.parent()
        {
            let stdlib = parent.join("stdlib");
            if stdlib.exists() {
                return Ok(stdlib);
            }
        }

        // Default location
        Ok(PathBuf::from("/usr/share/sounio/stdlib"))
    }

    fn index_ontology<T: OntologySource>(
        ontology: &T,
        prefix: &str,
        augmenter: &augmentation::EpistemicAugmenter,
        index: &mut HashMap<String, FoundationTerm>,
    ) {
        for entry in ontology.terms() {
            let key = format!("{}:{}", prefix, entry.id.id);

            // Compute initial epistemic status
            let initial_epistemic = augmenter.compute_initial_epistemic(
                &entry,
                ontology.curation_status(),
                ontology.provenance(),
            );

            // Get SSSOM mappings if available
            let mappings = ontology.get_mappings(&entry.id).unwrap_or_default();

            // Compute embedding for semantic similarity (optional)
            let embedding = augmenter.compute_embedding(&entry);

            index.insert(
                key,
                FoundationTerm {
                    entry,
                    initial_epistemic,
                    mappings,
                    embedding,
                },
            );
        }
    }

    /// Resolve a term from foundation ontologies
    pub fn resolve(&self, binding: &OntologyBinding) -> Option<FoundationTerm> {
        let key = format!("{:?}:{}", binding.ontology, binding.term.id);
        self.index.get(&key).cloned()
    }

    /// Get term by CURIE
    pub fn get(&self, curie: &str) -> Option<&FoundationTerm> {
        self.index.get(curie)
    }

    /// Find semantically similar terms across ontologies
    pub fn find_similar(&self, term: &TermId, threshold: f64) -> Vec<(FoundationTerm, f64)> {
        let source = self.index.values().find(|t| t.entry.id == *term);

        let source = match source {
            Some(s) => s,
            None => return vec![],
        };

        let source_embedding = match &source.embedding {
            Some(e) => e,
            None => return vec![],
        };

        let mut results: Vec<_> = self
            .index
            .values()
            .filter_map(|t| {
                let emb = t.embedding.as_ref()?;
                let similarity = cosine_similarity(source_embedding, emb);
                if similarity >= threshold && t.entry.id != *term {
                    Some((t.clone(), similarity))
                } else {
                    None
                }
            })
            .collect();

        results.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
        results
    }

    /// Get total term count
    pub fn term_count(&self) -> usize {
        self.index.len()
    }

    /// List all loaded ontologies with their term counts
    pub fn ontology_stats(&self) -> Vec<(&str, usize)> {
        vec![
            ("PATO", self.pato.terms().len()),
            ("UO", self.uo.terms().len()),
            ("IAO", self.iao.terms().len()),
            ("Schema.org", self.schema_org.terms().len()),
            ("FHIR", self.fhir.terms().len()),
        ]
    }
}

impl Default for FoundationOntologies {
    fn default() -> Self {
        Self::bootstrap()
    }
}

fn cosine_similarity(a: &[f32], b: &[f32]) -> f64 {
    if a.len() != b.len() || a.is_empty() {
        return 0.0;
    }

    let dot: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
    let norm_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();
    let norm_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();

    if norm_a == 0.0 || norm_b == 0.0 {
        return 0.0;
    }

    (dot / (norm_a * norm_b)) as f64
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_bootstrap_loads() {
        let foundations = FoundationOntologies::bootstrap();
        assert!(foundations.term_count() > 0);
    }

    #[test]
    fn test_ontology_stats() {
        let foundations = FoundationOntologies::bootstrap();
        let stats = foundations.ontology_stats();
        assert_eq!(stats.len(), 5);

        for (name, count) in stats {
            println!("{}: {} terms", name, count);
            assert!(count > 0, "{} should have terms", name);
        }
    }

    #[test]
    fn test_mapping_predicate_confidence() {
        assert_eq!(MappingPredicate::ExactMatch.confidence_factor(), 1.0);
        assert!(MappingPredicate::CloseMatch.confidence_factor() > 0.9);
        assert!(MappingPredicate::RelatedMatch.confidence_factor() < 0.7);
    }

    #[test]
    fn test_curation_status_confidence() {
        assert!(CurationStatus::ExpertCurated.base_confidence() > 0.95);
        assert!(CurationStatus::AutoGenerated.base_confidence() < 0.8);
    }

    #[test]
    fn test_cosine_similarity() {
        let a = vec![1.0, 0.0, 0.0];
        let b = vec![1.0, 0.0, 0.0];
        assert!((cosine_similarity(&a, &b) - 1.0).abs() < 0.001);

        let c = vec![0.0, 1.0, 0.0];
        assert!(cosine_similarity(&a, &c).abs() < 0.001);
    }
}
